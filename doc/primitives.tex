\chapter{Primitive Types}

\section{Numbers}

% everything is a number, not always obvious, classes of numbers, the simples calls is integers
All values that we may want to work with in a computer are, one way or the other, \idx{numbers}{Number}. This fact may not always be obvious, but it will be quite a while before you encounter such examples. From public school and highschool, we know these classes of numbers:
\begin{itemize}
  \descitem{The \idx{natural numbers}{Numbers!Natural}} ($\mathbb{N}$) These are the non-negative numbers that can be written without a decimal point\footnote{There are two definitions of natural numbers. The other definition is that they are the positive numbers that can be written without a decimal point. That is to say, without zero. As this definition is generally less applicable in computers, we stick to the first definition.}.
  \descitem{The \idx{integers}{Numbers!Integer}} ($\mathbb{Z}$) These are all the natural numbers (according to the first definition) along with the negative versions of the natural numbers (according to the second definition). That definition juggling is to make sure that we don't have a negative zero.
  \descitem{The \idx{real numbers}{Numbers!Real}} ($\mathbb{R}$) These are all the numbers that can be placed on a line between $-\infty$ and $\infty$. We often refer to these as floating point numbers.
  \descitem{The \idx{rational numbers}{Numbers!Rational}} ($\mathbb{Q}$) These are then numbers that can be written as the fraction $m/n$ where $m \in \mathbb{Z}$ and $m \in \mathbb{N}$.
  \descitem{The \idx{irrational numbers}{Numbers!Irrational}} ($\mathbb{P}$) These are numbers that belong to $\mathbb{R}$ but not $\mathbb{Q}$. This is where $\pi$ and $e$ belong.
\end{itemize}
Computers typically works with other classes of numbers. In the following sections, we will explore the most commonly used ones. Common to these is that they are all \idx{represented in binary}{Representation!Binary} numbers. That is, using the \idx{base-2}{Base 2} digits. We are used to working with \idx{base-10}{Base 10} where numbers are digits between zero and nine. In base-2, the numbers are made up of digits between zero and one (i.e., \texttt{0} or \texttt{1}). Such a digit is called a \defi{bit}{Bit}, and a sequence of eight bits is referred to as a \defi{byte}{Byte}. The plural forms of the singular bit and byte is bits and bytes. Bits are, by the way, the \idx{SI unit}{SI unit} of information, in the same way as meter is the SI unit of distance. Accordingly, we measure \idx{information}{Information} in bits.

\section{Integers}

% how we know them (no decimal point), what we use them for (typically counts and variants thereof)
We recognize integers as numbers without a decimal point. We use them for counting, and variants thereof. A human may have two or three siblings. But if I were to tell you that I know someone who has 2.3 siblings then you would begin to question my faculties.

\subsection{Operations}

% basic operations
All general purpose languages support the four basic \idx{arithmetic operators}{Operation!Arithmetic} for addition, subtraction, multiplication and division of integers. The tree first of these will guarantee an integral result. For instance, if you add two integers, you will get an integer. The \textsl{size} of this integer may be affected though. But more on that in section \ref{primitives:int:representation}.

% that division thing
That rule, about the result of an operation resulting in an integral value does not hold for the \idx{division}{Operation!Division} operation though. Mathematically, the result \textsl{may} be integral, but generally speaking there is no guarantee, and more often than not it is simply not the case. Most programming languages supports two types of division; namely \idx{integer division}{Operation!Division!Integer} and \idx{floating-point division}{Operation!Division!Floating-point}. The result of a floating-point division is a floating-point number as introduced in section \ref{primitives:float}. The result of an integer division is an integer.

% remainder vs modulo
This operation is tightly coupled to both the \idx{remainder}{Remainder} and the \idx{modulo}{Modulo} operations. The difference between these is how they handle negative numbers.

% TODO: Figure of remainder vs modulo

\subsection{Representation}
\label{primitives:int:representation}

% intro: decimal (least significant digit to the right, 10 values for each digit, 10x difference between significance of neighboring digits), same for binary
We all know the \idx{decimal numeral system}{Decimal numeral system}. That is, the way we represent numbers using \idx{base-10}{Base-10} positioning of digits. In the west, we write the least significant digit to the right. There are ten potential values for each digit and a 10x order of magnitude between two successive digits. The same goes for \idx{binary}{Binary} (or \idx{base-2}{Base-2}). We write the least significant digit to the right, we have two potential values for each digit (zero and one), and the difference between two neighboring digits is a factor of two. Binary values are often \idx{prefixed}{Prefix!Number} by \say{0b}. Figure \ref{fig:prim:int:repr:base} illustrates how to interpret a binary number.

\begin{figure}[tbp]
  \input{figs/prim_int_repr_base.tex}
  \caption{Representation of numbers in decimal and binary.}
  \label{fig:prim:int:repr:base}
\end{figure}

% integer size
Normally, when we write out a number, we don't care about how much space it takes up. We have a need to represent the number and it takes up the space it takes up. Space is not an issue. But in a computer, that number need to be worked on by the machine (see section \ref{sec:machine}). The \idx{ALU}{ALU} has to be designed for parameters of a specific number of bits, and the instructions for loading and storing register values have to be designed for a specific number of bits. While the hardware support doesn't necessarily put hard restrictions on what we can do, it does dictate which sizes of integers will be \idx{efficient}{Efficiency} for us to work with. These are usually calculated in bytes and measured in powers of two. Common examples are 1, 2, 4, and 8 bytes, or the corresponding 8, 16, 32 and 64 bits.

% hex
Often, you will also come across \idx{hexadecimal}{Hexadecimal} representation, which is still the same only \idx{base-16}{Base-16}. But here we run into a problem: While it is easy how to represent the ten lowest valued digits in a 16 digit system (i.e., 0 through 9), what do you the with the remaining six? How about eleven? Obviously, we could call it 11. But the consequence of that would be that we would either have to use two characters for each digit (e.g., 06 for 6), or rely on some other formatting trick (e.g., \{1,7,12,14,3\}) to be able to unambiguously decode a number. Both solutions are cumbersome and take up space. Instead, we usually say that eleven is \say{a}, twelve is \say{b} and so on. Then a digit is still a single character, and this allows us to write a number compactly. \idx{Hex values}{Value!Hex}, as these are called, are often prefixed by \say{0x}. An example of such a value is 0x04ff2b.

% binary example, and how to read it %TODO: Is this still relevant with the next paragraph?

% operations: essentially work like we are used to from decimal, ref to fig, overflow
The binary notation is convenient when we think about how the numbers are represented in the machine. Operations are performed in pretty much the same way that you are used to from decimal numbers. Figure \ref{fig:prim:int:binary:add} illustrates how to add two binary numbers. If you squint your eyes, you should recognize something familiar. The main difference is that when we are doing calculations on a piece of paper, we can pretty much keep on adding digits. In a computer we have a fixed number of digits. And when we run out of digits, we get a wrong result. For instance, the highest number that we can represent consist of all one digits. If we were to add the number one to this number, then the carry travels all the way through the digits in ascending order thereby clearing all bits. This is called an \defi{overflow}{Overflow}. The series of numbers that can be represented essentially loops around so that the largest integer that can be represented (the so-called \defi{MAXINT}{MAXINT@\textsl{MAXINT}}) comes just before zero.

\begin{figure}[tbp]
  \input{figs/prim_int_binary_add.tex}
  \caption{Addition of two 8-bit binary numbers.}
  \label{fig:prim:int:binary:add}
\end{figure}

% signedness: two's compliment

\csharpsubsection{\csharp}

% integer types available: and how to pick
\csharp\ supports the signed and unsigned integer types listed in figure \ref{fig:prim:int:csharp:types}. Lets say that you need to be able to represent any positive number below 100.000. That number sits somewhere in between the limits of 16 bits and 32 bits. This means that we need at least 32 bits, and if we use more than 32 bits to represent it then we will be wasting memory. Depending on our \idx{architecture}{Architecture!Processor}, there might be processing speed to \idx{trade}{Tradeoff} for this \say{wasted} memory. But lets just stick to the 32 bits for now. As we don't need the negative values we will go for an \typename{int}.

\begin{figure}[tbp]
  \input{figs/prim_int_csharp_types.tex}
  \caption{Integer types available in \csharp.}
  \label{fig:prim:int:csharp:types}
\end{figure}

% native types
That last line on the table is a little bit different though. You may have noticed that it is measured in \idx{words}{Word} instead of bits or bytes. On most processor architectures, a word will be defined as either 32 bits or 64 bits. See it as the most efficient integer size. The \typename{n} in \typename{nuint} and \typename{nint} stands for \textsl{\idx{native}{Native}}. A side-effect of using these types is that the effective MAXINT is machine dependent, and that can cause \idx{portability}{Portability} issues if you are not careful. For now, just stay away from these two types.

% naming conventions
The naming convention of the integer types is a bit unfortunate from a consistency perspective. The \typename{u} prefix is used to denote an \idx{unsigned}{Unsigned} variant, except for the \typename{byte} case where the \typename{s} prefix is used to denote an \idx{signed}{Signed} variant. In \typename{nuint} the \typename{u} still denotes something that is unsigned but it is not at the beginning of the name. So, from a human side, parsing these names if a relatively complex task. With a bit of experience though, you won't notice.

% what is the result of int32+int32? what is an overflow? %TODO: this was written higher up. Is that okay?

\subsubsection{Expressions}

% printing out expressions
The following line prints out \say{42} to the screen:
\begin{minted}{csharp}
Console.WriteLine(42);
\end{minted}

% explanation, tokens, literal definition
Then the \idx{lexer}{Lexer} is fed this program, it produces the token sequence of figure \ref{fig:primitives:int:tokens}. The \texttt{INT} token represents a concrete \typename{int} value that was embedded in the input source code. Such values embedded in source code are called \defi{literals}{Literal}. Literal forms exist for most of the primitive types.

% fig: int literals in token sequence
\begin{figure}[tbp]
  \input{figs/primitives_int_tokens.tex}
  \caption{Token sequence of a program the prints out an integer.}
  \label{fig:primitives:int:tokens}
\end{figure}

% extend the set of expression forms: literal forms
It is a bit more complicated than that though: Literals are \defi{typed}{Typed}. That means that the compiler sees it as having a type in addition to having a value. So, in the previous example, that \texttt{42} part of the code represented an \typename{int} with a value of $42$. We know this because of the \idx{literal specifier}{Literal!Specifier} rules of \csharp. For integers, the rules are listed in figure \ref{fig:primitives:int:literals}.

% fig: literal specifiers
\begin{figure}[tbp]
  \input{figs/primitives_int_literals.tex}
  \caption{Literal specifiers for integer values.}
  \label{fig:primitives:int:literals}
\end{figure}

% syntax: int, uint, long, ulong as expressions
Literals in general, and integer literals in particular, are expressions. That means that we can extend our set of syntax rules with the set from syntax \ref{syntax:prim:int:literals}. This is the reason why the line of code from the beginning of this section is \idx{syntactically valid}{Validity!Syntactic}.

\begin{syntaxfloat}
  \input{syntax/prim_int_literals.tex}
  \caption{Expressions of integer literals}
  \label{syntax:prim:int:literals}
\end{syntaxfloat}

\subsubsection{Operations}

% set of operations

\begin{syntaxfloat}
  \input{syntax/prim_arithmetic_ops.tex}
  \caption{Expressions of arithmetic operators}
  \label{syntax:prim:arithmetic:ops}
\end{syntaxfloat}

% example

\elixirsubsection{Elixir}

% arbitrary sizes: pros
In Elixir, there is only one integer type and that has an \idx{arbitrary size}{Arbitrary size}. As long as an integral value fits in memory, an Elixir integer can hold it. The value is not in having integers that each take up 90\% of your \idx{primary memory}{Memory!Primary}. It is very rare that we have a need for integers beyond 128 bits or even 64 bits. But when we work with \idx{fixed size}{Fixed size} integers, we always have to be aware of that hard limit. In Elixir, we don't have to: If we somehow end up with a number needing 7000 bits, then that is what gets allocated. We don't have to worry.

% and cons, why the tradeoff was resolved in this way
Elixir code, still runs on the same hardware though. This hardware does not have instructions capable of operating on 7000 bit integers. So, instead of an integer operation being a single \idx{instruction}{Instruction}, it is an \idx{algorithm}{Algorithm} in itself. This is significantly slower. Elixir is designed for network intensive tasks, and these are even slower. So, for the tasks where one would choose Elixir, it basically doesn't matter. And that is why the designers of that language has made that choice.

\section{Floating Point Numbers}
\label{primitives:float}

\subsection{Operations}
\subsection{Representation}
\csharpsubsection{\csharp}
\elixirsubsection{Elixir}

\section{Truth Values}
\label{primitives:bools}

% what do they represent

\subsection{Operations on Nontruthy Values}

Any valid comparison between two nontruthy values will yield a truthy value. For instance, if we ask \quoted{is 42 equal to 56?} then the resulting value is \valuename{false} but if we ask \quoted{is 1 less than or equal to 2?} then the resulting value is \valuename{true}. The full set of comparison operators are listed in figure \ref{fig:prim:bool:comparison}. This is one of the primary ways of creating boolean values.

\begin{figure}[tbp]
  \input{figs/prim_bool_comp.tex}
  \caption{Comparison operators.}
  \label{fig:prim:bool:comparison}
\end{figure}

\subsection{Operations on Truth Values}

\begin{figure}[tbp]
  \input{figs/prim_bool_and.tex}
  \caption{Truth table for the boolean operations.}
  \label{fig:prim:bool:and}
\end{figure}

% TODO: De Morgan's law

\subsection{Representation}

% technically a bit, but typically (mostly unless in array form) a byte or word

\csharpsubsection{\csharp}

\begin{syntaxfloat}
  \input{syntax/prim_bool_ops.tex}
  \caption{Expressions of boolean operators}
  \label{syntax:prim:bool:ops}
\end{syntaxfloat}

\elixirsubsection{Elixir}

\csubsection{C}

% low-level language
\idx{C}{Language!C} is a simple \idx{low-level language}{Language!Low-level}. That means that it mirrors the fundamental properties of the underlying harware and adds some highly convenient abstractions. These abstractions are chosen is such a way that they essentially can be delivered without a performance overhead.

% consequence: a boolean is a register
\idxx{Machine code} does not have a boolean type. Instead \idx{register}{Register} values that are represented using all zeroes in binary are \textsl{false} and every other value is \textsl{true}. That means -- in terms of integers -- that zero is \textsl{false} and non-zero is \textsl{true}. % TODO: Explain the !!42 == 1 situation, word for reference/strong true values, implicit konvertering til bool i condition af en if

% consequence: a bool is an integer and can thus be used in an integer expression
A consequence of this is that C doesn't have a notion of a \idx{boolean}{Boolean}. Instead, integers are used: A boolean is an interpretation of an integer, and can thus be used in an integer expression. Typically, this will make absolutely no difference. Proponents of \csharp\ will point out that booleans and integers are fundamentally different notions and should thus be treated differently. Proponents of C will point out that this allows them to write code such as this:

% TODO: Example

% explanation: why is this clever (no branches gives execution speed, and it is still readable)

\section{Local Variables}
\csharpsubsection{\csharp}

\begin{syntaxfloat}
  \input{syntax/prim_vars_locals.tex}
  \caption{Local variables.}
  \label{syntax:prim:vars:locals}
\end{syntaxfloat}

\elixirsubsection{Elixir}

\section{Parsing}
\subsection{Operator Precedence}

% parentheses

\subsection{Operator Associativity}

\csharpsubsection{\csharp}

\begin{syntaxfloat}
  \input{syntax/prim_pars.tex}
  \caption{Expressions of parentheses}
  \label{syntax:prim:pars}
\end{syntaxfloat}

\exercises{primitives}{Primitive Types}

