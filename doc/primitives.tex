\chapter{Primitive Types}

\section{Numbers}

% everything is a number, not always obvious, classes of numbers, the simples calls is integers
All values that we may want to work with in a computer are, one way or the other, \idx{numbers}{Number}. This fact may not always be obvious, but it will be quite a while before you encounter such examples. From public school and highschool, we know these classes of numbers:
\begin{itemize}
  \descitem{The \idx{natural numbers}{Numbers!Natural}} ($\mathbb{N}$) These are the non-negative numbers that can be written without a decimal point\footnote{There are two definitions of natural numbers. The other definition is that they are the positive numbers that can be written without a decimal point. That is to say, without zero. As this definition is generally less applicable in computers, we stick to the first definition.}.
  \descitem{The \idx{integers}{Numbers!Integer}} ($\mathbb{Z}$) These are all the natural numbers (according to the first definition) along with the negative versions of the natural numbers (according to the second definition). That definition juggling is to make sure that we don't have a negative zero.
  \descitem{The \idx{real numbers}{Numbers!Real}} ($\mathbb{R}$) These are all the numbers that can be placed on a line between $-\infty$ and $\infty$. We often refer to these as floating point numbers.
  \descitem{The \idx{rational numbers}{Numbers!Rational}} ($\mathbb{Q}$) These are then numbers that can be written as the fraction $m/n$ where $m \in \mathbb{Z}$ and $m \in \mathbb{N}$.
  \descitem{The \idx{irrational numbers}{Numbers!Irrational}} ($\mathbb{P}$) These are numbers that belong to $\mathbb{R}$ but not $\mathbb{Q}$. This is where $\pi$ and $e$ belong.
\end{itemize}
Computers typically works with other classes of numbers. In the following sections, we will explore the most commonly used ones. Common to these is that they are all \idx{represented in binary}{Representation!Binary} numbers. That is, using the \idx{base-2}{Base 2} digits. We are used to working with \idx{base-10}{Base 10} where numbers are digits between zero and nine. In base-2, the numbers are made up of digits between zero and one (i.e., \texttt{0} or \texttt{1}). Such a digit is called a \defi{bit}{Bit}, and a sequence of eight bits is referred to as a \defi{byte}{Byte}. The plural forms of the singular bit and byte is bits and bytes. Bits are, by the way, the \idx{SI unit}{SI unit} of information, in the same way as meter is the SI unit of distance. Accordingly, we measure \idx{information}{Information} in bits.

\section{Integers}

% how we know them (no decimal point), what we use them for (typically counts and variants thereof)
We recognize integers as numbers without a decimal point. We use them for counting, and variants thereof. A human may have two or three siblings. But if I were to tell you that I know someone who has 2.3 siblings then you would begin to question my faculties.

\subsection{Operations}

% basic operations
All general purpose languages support the four basic \idx{arithmetic operators}{Operation!Arithmetic} for addition, subtraction, multiplication and division of integers. The tree first of these will guarantee an integral result. For instance, if you add two integers, you will get an integer. The \textsl{size} of this integer may be affected though. But more on that in section \ref{primitives:int:representation}.

% that division thing
That rule, about the result of an operation resulting in an integral value does not hold for the \idx{division}{Operation!Division} operation though. Mathematically, the result \textsl{may} be integral, but generally speaking there is no guarantee, and more often than not it is simply not the case. Most programming languages supports two types of division; namely \idx{integer division}{Operation!Division!Integer} and \idx{floating-point division}{Operation!Division!Floating-point}. The result of a floating-point division is a floating-point number as introduced in section \ref{primitives:float}. The result of an integer division is an integer.

% remainder vs modulo
This operation is tightly coupled to both the \idx{remainder}{Remainder} and the \idx{modulo}{Modulo} operations. The difference between these is how they handle negative numbers.

% TODO: Figure of remainder vs modulo

\subsection{Representation}
\label{primitives:int:representation}

% intro: decimal (least significant digit to the right, 10 values for each digit, 10x difference between significance of neighboring digits), same for binary
We all know the \idx{decimal numeral system}{Decimal numeral system}. That is, the way we represent numbers using \idx{base-10}{Base-10} positioning of digits. In the west, we write the least significant digit to the right. There are ten potential values for each digit and a 10x order of magnitude between two successive digits. The same goes for \idx{binary}{Binary} (or \idx{base-2}{Base-2}). We write the least significant digit to the right, we have two potential values for each digit (zero and one), and the difference between two neighboring digits is a factor of two. Binary values are often \idx{prefixed}{Prefix!Number} by \say{0b}. Figure \ref{fig:prim:int:repr:base} illustrates how to interpret a binary number.

\begin{figure}[tbp]
  \input{figs/prim_int_repr_base.tex}
  \caption{Representation of numbers in decimal and binary.}
  \label{fig:prim:int:repr:base}
\end{figure}

% integer size
Normally, when we write out a number, we don't care about how much space it takes up. We have a need to represent the number and it takes up the space it takes up. Space is not an issue. But in a computer, that number need to be worked on by the machine (see section \ref{sec:machine}). The \idx{ALU}{ALU} has to be designed for parameters of a specific number of bits, and the instructions for loading and storing register values have to be designed for a specific number of bits. While the hardware support doesn't necessarily put hard restrictions on what we can do, it does dictate which sizes of integers will be \idx{efficient}{Efficiency} for us to work with. These are usually calculated in bytes and measured in powers of two. Common examples are 1, 2, 4, and 8 bytes, or the corresponding 8, 16, 32 and 64 bits.

% hex
Often, you will also come across \idx{hexadecimal}{Hexadecimal} representation, which is still the same only \idx{base-16}{Base-16}. But here we run into a problem: While it is easy how to represent the ten lowest valued digits in a 16 digit system (i.e., 0 through 9), what do you the with the remaining six? How about eleven? Obviously, we could call it 11. But the consequence of that would be that we would either have to use two characters for each digit (e.g., 06 for 6), or rely on some other formatting trick (e.g., \{1,7,12,14,3\}) to be able to unambiguously decode a number. Both solutions are cumbersome and take up space. Instead, we usually say that eleven is \say{a}, twelve is \say{b} and so on. Then a digit is still a single character, and this allows us to write a number compactly. \idx{Hex values}{Value!Hex}, as these are called, are often prefixed by \say{0x}. An example of such a value is 0x04ff2b.

% binary example, and how to read it %TODO: Is this still relevant with the next paragraph?

% operations: essentially work like we are used to from decimal, ref to fig, overflow
The binary notation is convenient when we think about how the numbers are represented in the machine. Operations are performed in pretty much the same way that you are used to from decimal numbers. Figure \ref{fig:prim:int:binary:add} illustrates how to add two binary numbers. If you squint your eyes, you should recognize something familiar. The main difference is that when we are doing calculations on a piece of paper, we can pretty much keep on adding digits. In a computer we have a fixed number of digits. And when we run out of digits, we get a wrong result. For instance, the highest number that we can represent consist of all one digits. If we were to add the number one to this number, then the carry travels all the way through the digits in ascending order thereby clearing all bits. This is called an \defi{overflow}{Overflow}. The series of numbers that can be represented essentially loops around so that the largest integer that can be represented (the so-called \defi{MAXINT}{MAXINT@\textsl{MAXINT}}) comes just before zero.

\begin{figure}[tbp]
  \input{figs/prim_int_binary_add.tex}
  \caption{Addition of two 8-bit binary numbers.}
  \label{fig:prim:int:binary:add}
\end{figure}

% signedness: two's compliment

\csharpsubsection{\csharp}

% integer types available: and how to pick
\csharp\ supports the signed and unsigned integer types listed in figure \ref{fig:prim:int:csharp:types}. Lets say that you need to be able to represent any positive number below 100.000. That number sits somewhere in between the limits of 16 bits and 32 bits. This means that we need at least 32 bits, and if we use more than 32 bits to represent it then we will be wasting memory. Depending on our \idx{architecture}{Architecture!Processor}, there might be processing speed to \idx{trade}{Tradeoff} for this \say{wasted} memory. But lets just stick to the 32 bits for now. As we don't need the negative values we will go for an \typename{int}.

\begin{figure}[tbp]
  \input{figs/prim_int_csharp_types.tex}
  \caption{Integer types available in \csharp.}
  \label{fig:prim:int:csharp:types}
\end{figure}

% native types
That last line on the table is a little bit different though. You may have noticed that it is measured in \idx{words}{Word} instead of bits or bytes. On most processor architectures, a word will be defined as either 32 bits or 64 bits. See it as the most efficient integer size. The \typename{n} in \typename{nuint} and \typename{nint} stands for \textsl{\idx{native}{Native}}. A side-effect of using these types is that the effective MAXINT is machine dependent, and that can cause \idx{portability}{Portability} issues if you are not careful. For now, just stay away from these two types.

% naming conventions
The naming convention of the integer types is a bit unfortunate from a consistency perspective. The \typename{u} prefix is used to denote an \idx{unsigned}{Unsigned} variant, except for the \typename{byte} case where the \typename{s} prefix is used to denote an \idx{signed}{Signed} variant. In \typename{nuint} the \typename{u} still denotes something that is unsigned but it is not at the beginning of the name. So, from a human side, parsing these names if a relatively complex task. With a bit of experience though, you won't notice.

% what is the result of int32+int32? what is an overflow? %TODO: this was written higher up. Is that okay?

\subsubsection{Expressions}

% printing out expressions
The following line prints out \say{42} to the screen:
\begin{minted}{csharp}
Console.WriteLine(42);
\end{minted}

% explanation, tokens, literal definition
Then the \idx{lexer}{Lexer} is fed this program, it produces the token sequence of figure \ref{fig:primitives:int:tokens}. The \texttt{INT} token represents a concrete \typename{int} value that was embedded in the input source code. Such values embedded in source code are called \defi{literals}{Literal}. Literal forms exist for most of the primitive types.

% fig: int literals in token sequence
\begin{figure}[tbp]
  \input{figs/primitives_int_tokens.tex}
  \caption{Token sequence of a program the prints out an integer.}
  \label{fig:primitives:int:tokens}
\end{figure}

% extend the set of expression forms: literal forms
It is a bit more complicated than that though: Literals are \defi{typed}{Typed}. That means that the compiler sees it as having a type in addition to having a value. So, in the previous example, that \texttt{42} part of the code represented an \typename{int} with a value of $42$. We know this because of the \idx{literal specifier}{Literal!Specifier} rules of \csharp. For integers, the rules are listed in figure \ref{fig:primitives:int:literals}.

% fig: literal specifiers
\begin{figure}[tbp]
  \input{figs/primitives_int_literals.tex}
  \caption{Literal specifiers for integer values.}
  \label{fig:primitives:int:literals}
\end{figure}

% syntax: int, uint, long, ulong as expressions
Literals in general, and integer literals in particular, are expressions. That means that we can extend our set of syntax rules with the set from syntax \ref{syntax:prim:int:literals}. This is the reason why the line of code from the beginning of this section is \idx{syntactically valid}{Validity!Syntactic}.

\begin{syntaxfloat}
  \input{syntax/prim_int_literals.tex}
  \caption{Expressions of integer literals}
  \label{syntax:prim:int:literals}
\end{syntaxfloat}

\subsubsection{Operations}

% set of operations

\begin{syntaxfloat}
  \input{syntax/prim_arithmetic_ops.tex}
  \caption{Expressions of arithmetic operators}
  \label{syntax:prim:arithmetic:ops}
\end{syntaxfloat}

% example

\elixirsubsection{Elixir}

% arbitrary sizes: pros
In Elixir, there is only one integer type and that has an \idx{arbitrary size}{Arbitrary size}. As long as an integral value fits in memory, an Elixir integer can hold it. The value is not in having integers that each take up 90\% of your \idx{primary memory}{Memory!Primary}. It is very rare that we have a need for integers beyond 128 bits or even 64 bits. But when we work with \idx{fixed size}{Fixed size} integers, we always have to be aware of that hard limit. In Elixir, we don't have to: If we somehow end up with a number needing 7000 bits, then that is what gets allocated. We don't have to worry.

% and cons, why the tradeoff was resolved in this way
Elixir code, still runs on the same hardware though. This hardware does not have instructions capable of operating on 7000 bit integers. So, instead of an integer operation being a single \idx{instruction}{Instruction}, it is an \idx{algorithm}{Algorithm} in itself. This is significantly slower. Elixir is designed for network intensive tasks, and these are even slower. So, for the tasks where one would choose Elixir, it basically doesn't matter. And that is why the designers of that language has made that choice.

\section{Floating Point Numbers}
\label{primitives:float}

We use integers to express a number of whole units. The number itself does not tell us what that unit is. That depends on what the integer represents. What it is used for. Decimal numbers, on the other hand, are use to express numbers are a \idx{granularity}{Granularity} that is higher than one unit. That is, they can express fractional units. A recipe for an omelet might state that you need $1.5$ eggs per person. We can't represent those $1.5$ using an integer type. For that, we need a decimal (or \idx{floating-point}{Floating-point type}) type.

\subsection{Operations}
\subsection{Representation}
\csharpsubsection{\csharp}
\elixirsubsection{Elixir}

\section{Set Theory}
\label{primitives:sets}

% why we won't cover sets (in this section): not primitive values

\section{Truth Values}
\label{primitives:bools}

% intro: what they are
So far, we have covered numbers. Integers of various sizes and signedness, and decimal numbers of different range and precision. A 32 bit unsigned integer is capable of representing any value between $0$ and $2^{32}-1$ (both included). Similarly, a 1 bit integer would be able to represent exactly two values: $0$ and $1$. Sets of integers go, that is not particularly useful. But, if we look past the individual numerical values, being able to represent that something has one of two states (e.g., on/off or open/closed) certainly is. 

% what do they represent
One particular pair of states is especially useful for us: Truth values. It allows is to represent whether something is \idx{true}{True} or \idx{false}{False}. In reality we map $0$ to false and $1$ to true. That is, we have the value mapping: $\{0 \mapsto \mathrm{false}, 1 \mapsto \mathrm{true}\}$. As the concept of truth values was introduced by \idx{George Boole}{Boole!George}, we have come to refer to these values as \idx{booleans}{Boolean} or, in short, \textsl{bools}.

\subsection{Operations on Numerical Values}

Any valid comparison between two numerical values will yield a truth value. For instance, if we ask \quoted{is 42 equal to 56?} then the resulting value is \valuename{false} but if we ask \quoted{is 1 less than or equal to 2?} then the resulting value is \valuename{true}. Comparing values is one of the primary ways of creating boolean values.


\subsection{Operations on Truth Values}

% the role of booleans extend beyond that of representing the result of some comparison, there is a whole algebra for it
Booleans are, however, not just something that can be used to represent the outcome of some comparison. In fact, there is a whole algebra built around this type. We will cover the following operations:
\begin{itemize}
  \descitem{NOT Operator} Whether a value is not true (aka whether it is false). It is written as $\neg a$. A door is open if it is not closed: $open = \neg closed$.
  \descitem{AND Operator} Whether two values are both true. It is written as $a \wedge b$. You are free to go if you have a green light and the road is clear: $free\_to\_go = green\_light \wedge clear\_road$. 
  \descitem{OR Operator} Whether at least one of two values is true. It is written as $a \vee b$. A plant will die if kept dry or in darkness: $will\_die = dry \vee darkness$.
  \descitem{XOR Operator (pronounced X-OR)} Whether exactly one of two values is true. It is written as $a \oplus b$. A swinging door will open if it is either being pushed or being pulled: $will\_open = pushed \oplus pulled$.
\end{itemize}

It is common to demonstrate operations on boolean values using a so-called \idx{truth table}{Truth table} such as the one in figure \ref{fig:prim:bool:ops}. The leftmost columns represent the input parameters. Any additional columns represent operations on these. Each column is labeled, and there is one row for each possible combination of the inputs. Truth tables can be used to document the \idx{behavior}{Behavior!Operator} of an operator or verify that two operations are equal under all input.

\begin{figure}[tbp]
  \input{figs/prim_bool_ops.tex}
  \caption{Truth table for the boolean operations.}
  \label{fig:prim:bool:ops}
\end{figure}

% differentiating between OR and XOR: XOR not being considered one of the basic operators, can both inputs be true? (then it doesn't matter and we normally use OR), are both allowed to be true?, example(game is over if you win or die)
The XOR operator is not considered one of the \textsl{basic} boolean operators, and it is also -- by some margin -- the least used one. It can be hard to differentiate between OR and XOR. For instance, be might say that a game is over if you win or if you die. Should you choose to define this using OR or XOR? The only difference between these operators is what happens if both are true, and that never happens in a game: You don't both win and die. So, in this case it doesn't really matter. When it doesn't matter, most programmers will chose OR. Probably because we consider it linguistically simpler. In other scenarios, the behavior when both inputs are true does matter, and then that becomes the \idx{arbiter}{Arbiter}.

% example: 
But, lets look at a real-world example. Imagine that we are building a game. In this game the player progresses through a sequence of levels. In order to progress to the next level, the player must at the end of the current level (i) be alive, and (ii) have obtained a certain number of points. After each level the number of required points is raised. Whether the player should progress can then be determined as $alive \wedge P \geq P_{required}$ or (depending on what we track) $\neg dead \wedge P \geq P_{required}$.

% TODO: relation to set theory

% De Morgan's laws
As we know from \idx{elementary algebra}{Algebra!Elementary}, there are rules for transforming certain constructs. For instance, we know that $a(b+c) = ab + ac$. Similar rules exist for \idx{boolean algebra}{Algebra!Boolean}. The two most important of these rules are known as \idx{De Morgan's Laws}{De Morgan's Laws} (after \idx{Augustus De Morgan}{De Morgan, Augustus}). They state that:
\begin{align*}
  \neg (A \vee B) &= (\neg A) \wedge (\neg B) \\
  \neg (A \wedge B) &= (\neg A) \vee (\neg B) 
\end{align*}
Or, in plain English, we have that:
\begin{enumerate}
  \item The negation of A or B is the same as (the negation of A) and (the negation of B).
  \item The negation of A and B is the same as (the negation of A) or (the negation of B).
\end{enumerate}

\subsection{Representation}

% technically a bit, but typically (mostly unless in array form) a byte or word
As mentioned, a boolean is a type that holds one of two values. That is a bit of information. However, in order to perform operations on a boolean, we need to store it in a register and common processors don't have these. Instead, booleans are placed in integer registers. Depending on the language and/or compiler may store the same booleans in main memory as bytes, integers (of register compatible size) or -- if there is a number of them -- packed into one byte per 8 booleans.

\csharpsubsection{\csharp}

% TODO: placing the introduction of the C# operators
It would be very tedious to use the symbols covered for AND, OR and NOT. \csharp, like many other languages, use a different notation:
\begin{itemize}
  \descitem{AND Operator} Two ampersands in a row is an \idx{infix}{infix} AND operator. \\
    Example: \texttt{unlocked \&\& open} should be read as \say{unlocked and open}.
  \descitem{OR Operator} Two vertical bars in a row is an \idx{infix}{infix} OR operator. \\
    Example: \texttt{working || waiting} should be read as \say{working or waiting}.
  \descitem{XOR Operator} A hat character is an \idx{infix}{infix} XOR operator. \\
    Example: \texttt{sunken \textasciicircum\ afloat} should be read as \say{sunken xor afloat} (as in, it cannot be both).
  \descitem{NOT Operator} An exclamation mark negates whatever condition comes after it. \\
    Example: \texttt{!ready} should be read as \say{not ready}.
\end{itemize}

% introduce syntax: new concept (cond), a cond is an expr that evaluates to a boolean value, a cond can take the form of a comparison or a boolean operator

The full set of comparison operators are listed in figure \ref{fig:prim:bool:comparison}.
\begin{figure}[tbp]
  \input{figs/prim_bool_comp.tex}
  \caption{Comparison operators.}
  \label{fig:prim:bool:comparison}
\end{figure}

% TODO: add comparisons
\begin{syntaxfloat}
  \input{syntax/prim_bool_ops.tex}
  \caption{Expressions of boolean operators}
  \label{syntax:prim:bool:ops}
\end{syntaxfloat}

% example
\begin{minted}{csharp}
bool progress = alive && (points > required_points);
\end{minted}

\subsubsection{Lazy Evaluation}

\elixirsubsection{Elixir}

% difference in naming operators: && -> and

\subsection{Low-Level Languages}

% low-level language
\idx{C}{Language!C} is a simple \idx{low-level language}{Language!Low-level}. That means that it mirrors the fundamental properties of the underlying harware and adds some highly convenient abstractions. These abstractions are chosen is such a way that they essentially can be delivered without a performance overhead.

% consequence: a boolean is a register
\idxx{Machine code} does not have a boolean type. Instead \idx{register}{Register} values that are represented using all zeroes in binary are \textsl{false} and every other value is \textsl{true}. That means -- in terms of integers -- that zero is \textsl{false} and non-zero is \textsl{true}. % TODO: Explain the !!42 == 1 situation, word for reference/strong true values, implicit konvertering til bool i condition af en if

% consequence: a bool is an integer and can thus be used in an integer expression
A consequence of this is that C doesn't have a notion of a \idx{boolean}{Boolean}. Instead, integers are used: A boolean is an interpretation of an integer, and can thus be used in an integer expression. Typically, this will make absolutely no difference. Proponents of \csharp\ will point out that booleans and integers are fundamentally different notions and should thus be treated differently. Proponents of C will point out that this allows them to write code such as this:

% TODO: Example

% explanation: why is this clever (no branches gives execution speed, and it is still readable)

\section{Local Variables}
\csharpsubsection{\csharp}

\begin{syntaxfloat}
  \input{syntax/prim_vars_locals.tex}
  \caption{Local variables.}
  \label{syntax:prim:vars:locals}
\end{syntaxfloat}

\elixirsubsection{Elixir}

\section{Parsing}

% intro: the code we write consists of a sequence of characters, C# will interpret this, we need to understand how it does this, otherwise how can we hope to "communicate" correctly with it?
When we are writing code, what we are really doing is to produce a sequence of characters. We store those in a file, and then ask the \csharp\ \idx{compiler}{Compiler} to interpret them. Given that \csharp\ is a language that we share with the compiler, we need a certain level of understanding of how it goes about interpreting it. Otherwise, how can we hope to \say{communicate} correctly with it?

% parsing: in this chapter we have introduced the notion of an expression, expressions are made up of operators, lets take a look at how expressions are parsed, that is: how a sequence of characters at a position in our code where the compiler expects an expression is translated into a parse tree
In this chapter, we have introduced the notion of an expression. Expressions are -- in part -- made up of operators. Lets take a look at how expressions are \idx{parsed}{Parsing}. That is, how does a sequence of characters, at a position in our code where the compiler expects an expression, get translated into a parse tree?

\subsection{Operator Precedence}

% intro: basic math tells us that $2+3*4=2+(3*4)=14$ as opposed to $(2+3)*4=24$, this is because we have agreed that a multiplication operation binds tighter than an addition, similar rules exist programming languages, and just as we learned that $2+3*4=2+(3*4)$ we need to learn how tightly each of the operators we make use of while programming bind

% grouping: 

% parentheses: when the precedence is not to our liking we use parentheses, novice programmers often sprinkle parentheses around their code, this becomes a source of confusion for more experienced programmers and is thus frowned upon

\subsection{Operator Associativity}

% question
We are not done yet though. Assuming that we have some operator -- lets call it $\odot$ -- and keeping in mind that the \idx{compiler}{Compiler} needs to convert any expression needs to be converted to a sequence of operations for the processor, how should $a \odot b \odot c$ be interpreted? By adding parentheses, we can remove this ambiguity. But, should $a \odot b \odot c$ be equal to $(a \odot b) \odot c$ or to $a \odot (b \odot c)$?

% why it matters
Given what we have covered so far, that question may not seem to matter. Most of the operators that we have covered exhibit the \idx{associative property}{Associative property}. That is, the order of evaluation does not affect the result. This changes, however, when composing complex expressions that modifies shared state (e.g., when pre-incrementing variables). From section \ref{sec:func} onward, we will cover operators that obviously does not have the associative property.

% solution
But lets get back to the question of where to place the parentheses. Some operators are left-associative, some are right-associative and some are non-associative. A \idx{left-associative operator}{Operator!Associativity!Left} is grouped from the left. This means that $a \odot b \odot c = (a \odot b) \odot c$, and that the syntax tree of a sequence of such operations skews heavily to the left-hand side. A \idx{right-associative operator}{Operator!Associativity!Right} is grouped from the right. This means that $a \odot b \odot c = a \odot (b \odot c)$, and that the syntax tree of a sequence of such operations skews heavily to the right-hand side. A \idx{non-associative operator}{Operator!Associativity!Non} is not allowed to appear in such a sequence.

% TODO: Add figure of the parse trees of $a \odot b \odot c \odot d$ given $\odot$ being left and right associative

\csharpsubsection{\csharp}

% https://learn.microsoft.com/en-us/dotnet/csharp/language-reference/operators/

\begin{syntaxfloat}
  \input{syntax/prim_pars.tex}
  \caption{Expressions of parentheses}
  \label{syntax:prim:pars}
\end{syntaxfloat}

\begin{figure}[tbp]
  \input{figs/prim_op_precedence.tex}
  \caption{Operator precedence levels.}
  \label{fig:prim:op:precedence}
\end{figure}

\exercises{primitives}{Primitive Types}

\section{Resolving Uncertainty}

% problem: c# is complex, we need to understand the underlying mechanisms to become good programmers, these mechanisms are not always simple and well documented, you will find yourself is situations where you are unsure of how the language works
\csharp is a complex language. That means that is takes a long time to master, even with effort. We need to study the underlying mechanisms to understand the language, and to (hopefully) become good programmers in the end. These mechanisms are not always simple and well documented. You will find yourself in situations where you are unsure of how the language works.

% consequences
Such situations has at least one of a number of negative consequences. If you are not aware of the disconnect between the language and your understanding of the language, then you may end up using sub-optimal programming constructs or you may introduce a bug.

% solution: poke the system
Awareness of the disconnect enables you to handle the situation constructively. See it as an opportunity to treat the situation with the respect (and time) it deserves: Read up on the relevant theory, or start poking it experimentally. Construct a piece of software with the single purpose of revealing \textsl{how} it behaves. This, with the intention of expanding your mental model of the language. Don't be afraid to get your hands dirty!

